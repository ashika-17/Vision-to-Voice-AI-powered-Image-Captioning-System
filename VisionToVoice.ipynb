{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rFj26hODeNc"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "!pip install gtts transformers torch pillow opencv-python googletrans==4.0.0-rc1\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import cv2\n",
        "import IPython.display as display\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "from gtts import gTTS\n",
        "from google.colab import files\n",
        "from google.colab import output\n",
        "import time\n",
        "import base64\n",
        "import numpy as np\n",
        "import io\n",
        "from googletrans import Translator\n",
        "\n",
        "# Load BLIP model and processor\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "# Function to capture image using Colab's webcam method\n",
        "def capture_image_colab():\n",
        "    from IPython.display import Javascript\n",
        "    from google.colab.output import eval_js\n",
        "    from base64 import b64decode\n",
        "\n",
        "    # JavaScript to capture image\n",
        "    js = Javascript('''\n",
        "        async function takePhoto() {\n",
        "            const div = document.createElement('div');\n",
        "            const video = document.createElement('video');\n",
        "            const capture = document.createElement('button');\n",
        "            capture.textContent = 'Capture Image';\n",
        "            div.appendChild(video);\n",
        "            div.appendChild(capture);\n",
        "            document.body.appendChild(div);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            video.srcObject = stream;\n",
        "            await new Promise((resolve) => video.onloadedmetadata = resolve);\n",
        "            video.play();\n",
        "\n",
        "            await new Promise((resolve) => capture.onclick = resolve);\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            stream.getTracks().forEach(track => track.stop());\n",
        "            div.remove();\n",
        "\n",
        "            return canvas.toDataURL('image/jpeg');\n",
        "        }\n",
        "    ''')\n",
        "    display.display(js)\n",
        "    image_data = eval_js('takePhoto()')\n",
        "\n",
        "    # Convert the base64 image to a PIL image\n",
        "    image_bytes = b64decode(image_data.split(',')[1])\n",
        "    image = Image.open(io.BytesIO(image_bytes))\n",
        "    image_path = \"captured_image.jpg\"\n",
        "    image.save(image_path)\n",
        "\n",
        "    print(\"‚úÖ Image Captured Successfully!\")\n",
        "    return image_path\n",
        "\n",
        "# Function to generate caption\n",
        "def generate_caption(image_path):\n",
        "    if not image_path:\n",
        "        print(\"‚ùå No image selected.\")\n",
        "        return None\n",
        "\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    display.display(image)  # Show image\n",
        "\n",
        "    # Process image\n",
        "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Generate caption\n",
        "    with torch.no_grad():\n",
        "        caption_ids = model.generate(**inputs)\n",
        "\n",
        "    caption = processor.batch_decode(caption_ids, skip_special_tokens=True)[0]\n",
        "    print(f\"üìù Generated Caption: {caption}\")\n",
        "    return caption\n",
        "\n",
        "# Function to translate text and play audio\n",
        "def play_audio(text, lang):\n",
        "    try:\n",
        "        translator = Translator()\n",
        "\n",
        "        # Translate only if the language is not English\n",
        "        if lang == \"ta\":\n",
        "            translated_text = translator.translate(text, dest=\"ta\").text\n",
        "        elif lang == \"hi\":\n",
        "            translated_text = translator.translate(text, dest=\"hi\").text\n",
        "        else:\n",
        "            translated_text = text  # No translation needed for English\n",
        "\n",
        "        print(f\"üìù Translated Caption: {translated_text}\")  # Display translated text\n",
        "\n",
        "        # Generate speech in the selected language\n",
        "        tts = gTTS(text=translated_text, lang=lang, slow=False)\n",
        "        audio_file = f\"caption_{lang}.mp3\"\n",
        "        tts.save(audio_file)\n",
        "\n",
        "        # Play the audio\n",
        "        display.display(display.Audio(audio_file, autoplay=True))\n",
        "        print(f\"üîä Playing caption audio in {lang}...\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Error generating audio:\", str(e))\n",
        "\n",
        "# Main program execution\n",
        "print(\"Choose an option:\")\n",
        "print(\"1Ô∏è‚É£ Upload an image\")\n",
        "print(\"2Ô∏è‚É£ Capture real-time image from webcam\")\n",
        "\n",
        "choice = input(\"Enter 1 or 2: \")\n",
        "\n",
        "if choice == \"1\":\n",
        "    print(\"üì§ Please upload an image...\")\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        image_path = list(uploaded.keys())[0]  # Get uploaded image path\n",
        "        print(\"‚úÖ Image Uploaded Successfully!\")\n",
        "    else:\n",
        "        print(\"‚ùå No image uploaded.\")\n",
        "        image_path = None\n",
        "\n",
        "elif choice == \"2\":\n",
        "    image_path = capture_image_colab()\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Invalid choice. Exiting program.\")\n",
        "    exit()\n",
        "\n",
        "# Process the selected image\n",
        "caption = generate_caption(image_path)\n",
        "\n",
        "if caption:\n",
        "    # Choose language for audio output\n",
        "    print(\"\\nüîä Choose an audio language:\")\n",
        "    print(\"1Ô∏è‚É£ English\")\n",
        "    print(\"2Ô∏è‚É£ Tamil\")\n",
        "    print(\"3Ô∏è‚É£ Hindi\")\n",
        "\n",
        "    lang_choice = input(\"Enter 1, 2, or 3: \")\n",
        "\n",
        "    lang_map = {\"1\": \"en\", \"2\": \"ta\", \"3\": \"hi\"}\n",
        "    lang = lang_map.get(lang_choice, \"en\")  # Default to English if invalid\n",
        "\n",
        "    play_audio(caption, lang)"
      ]
    }
  ]
}